{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# importing the tensorflow package\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.layers import SimpleRNN, LSTM, GRU\n",
    "\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Activation\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xiq0R-hnCu7j",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# IMDB reviews (keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2qU_kiLbC2jK",
    "outputId": "0e06ad04-2342-4bf3-d483-3a8f7fd055f5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_features = 25000\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room titillate it so heart shows to years of every never going villaronga help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but pratfalls to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other tricky in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of 'n odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\""
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the word index file mapping words to indices\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# Reverse the word index to obtain a dict mapping indices to words\n",
    "inverted_word_index = dict((i, word) for (word, i) in word_index.items())\n",
    "\n",
    "# Decode the first sequence in the dataset\n",
    "decoded_sequence = \" \".join(inverted_word_index[i] for i in x_train[0])\n",
    "\n",
    "decoded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MtJSwOPDC7__",
    "outputId": "f4977635-7bbf-4c44-dcfc-ec7f60b569cb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), 'тренировочные последовательности')\n",
    "print(len(x_test), 'тестовые последовательности')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CGAsy1MFDEVZ",
    "outputId": "43a45e8a-6e44-4ed6-e0a1-6b85b3d0fd7a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (25000, 200)\n",
      "x_test shape: (25000, 200)\n"
     ]
    }
   ],
   "source": [
    "# обрезание текстов после данного количества слов (среди top max_features наиболее используемые слова)\n",
    "maxlen = 200\n",
    "batch_size = 25 # увеличьте значение для ускорения обучения\n",
    "out_dim = 256\n",
    "dropout = 0.12\n",
    "epochs = 1\n",
    "\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SuCf2ixNDJ8m",
    "outputId": "56b46e29-4ad0-4dcd-918e-2887c954398e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, out_dim))\n",
    "model.add(GRU(out_dim, dropout=dropout , recurrent_dropout=dropout ))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "pKTWAEViFOdj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(learning_rate=0.0005)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "STDbV391GfDO",
    "outputId": "68b470ca-7816-4526-a9f3-799ca12546c9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процесс обучения...\n",
      "1000/1000 [==============================] - 1375s 1s/step - loss: 0.4366 - accuracy: 0.7903 - val_loss: 0.3511 - val_accuracy: 0.8524\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1acb5b79f10>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Процесс обучения...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09mnjJl0GlB7",
    "outputId": "e9673b14-5e9e-4809-e1e4-855afc0e00f4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 208s 208ms/step - loss: 0.3511 - accuracy: 0.8524\n",
      "Результат при тестировании: 0.35109177231788635\n",
      "Тестовая точность: 0.852400004863739\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Задание 1\n",
    "Положительный эффект на модель оказали следующие изменения:\n",
    "- увеличение количества признаков\n",
    "- увеличение количества слов в комментарии\n",
    "- уменьшение размера бача\n",
    "- снижение шумности данных\n",
    "- сменил модель на GRU"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "execution_count": 92
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xLGyQjYG3eq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Генерация текста на основе книжки «Алиса в стране чудес»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "0FoMKffgHIyR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# построчное чтение из примера с текстом \n",
    "with open(\"../input/alice_in_wonderland.txt\", 'rb') as _in:\n",
    "    lines = []\n",
    "    for line in _in:\n",
    "        line = line.strip().lower().decode(\"ascii\", \"ignore\")\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        lines.append(line)\n",
    "text = \" \".join(lines)\n",
    "chars = set(text)\n",
    "nb_chars = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "xlcUCnMRHfzk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# создание индекса символов и reverse mapping чтобы передвигаться между значениями numerical\n",
    "# ID and a specific character. The numerical ID will correspond to a column\n",
    "# ID и определенный символ. Numerical ID будет соответсвовать колонке\n",
    "# число при использовании one-hot кодировки для представление входов символов\n",
    "char2index = {c: i for i, c in enumerate(chars)}\n",
    "index2char = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "TQZaEpb-Hlyg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# для удобства выберете фиксированную длину последовательность 10 символов \n",
    "SEQLEN, STEP = 10, 1\n",
    "input_chars, label_chars = [], []\n",
    "\n",
    "# конвертация data в серии разных SEQLEN-length субпоследовательностей\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i: i + SEQLEN])\n",
    "    label_chars.append(text[i + SEQLEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BEMyktdvHqjc",
    "outputId": "0c0d6b26-f4d3-43d2-9901-917f9eaa6d27",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "('alices adv', 'e')"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_chars[0], label_chars[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9L3y9LfmHywZ",
    "outputId": "1192ea8e-a540-4367-9171-4663d2535497",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Вычисление one-hot encoding входных последовательностей X и следующего символа (the label) y\n",
    "\n",
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=bool)\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(139615, 10, 40)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "FWqwrcHiH6gw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# установка ряда метапамертров  для нейронной сети и процесса тренировки\n",
    "BATCH_SIZE, HIDDEN_SIZE = 128, 256\n",
    "NUM_ITERATIONS = 23 # 25 должно быть достаточно\n",
    "NUM_EPOCHS_PER_ITERATION = 2\n",
    "NUM_PREDS_PER_EPOCH = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(\n",
    "    LSTM(  # вы можете изменить эту часть на LSTM или SimpleRNN, чтобы попробовать альтернативы\n",
    "        HIDDEN_SIZE,\n",
    "        return_sequences=False,\n",
    "        input_shape=(SEQLEN, nb_chars),\n",
    "        unroll=True\n",
    "    )\n",
    ")\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CsGE7YUdITrA",
    "outputId": "7e54fc46-8b4d-498b-ec84-0399313d11f3",
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Итерация #: 1\n",
      "Epoch 1/2\n",
      "1091/1091 [==============================] - 48s 43ms/step - loss: 2.3201\n",
      "Epoch 2/2\n",
      "1091/1091 [==============================] - 45s 41ms/step - loss: 1.8707\n",
      "Генерация из посева: stily. con\n",
      "stily. cone the mouse the gry how in a dont on the said the gry how in a dont on the said the gry how in a dont on the said the gry how in a dont on the said the gry how in a dont on the said the gry how in a dont on the said the gry how in a dont on the said ==================================================\n",
      "Итерация #: 2\n",
      "Epoch 1/2\n",
      "1091/1091 [==============================] - 45s 41ms/step - loss: 1.6757\n",
      "Epoch 2/2\n",
      "1091/1091 [==============================] - 45s 41ms/step - loss: 1.5434\n",
      "Генерация из посева: of the e--\n",
      "of the e------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------==================================================\n",
      "Итерация #: 3\n",
      "Epoch 1/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 1.4405\n",
      "Epoch 2/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 1.3567\n",
      "Генерация из посева: et cushion\n",
      "et cushion, and the mock turtle was a large was the was a large was the was a large was the was a large was the was a large was the was a large was the was a large was the was a large was the was a large was the was a large was the was a large was the was a la==================================================\n",
      "Итерация #: 4\n",
      "Epoch 1/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 1.2857\n",
      "Epoch 2/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 1.2236\n",
      "Генерация из посева:  party wen\n",
      " party went on, and the mock turtle said to herself, and the mock turtle said to herself, and the mock turtle said to herself, and the mock turtle said to herself, and the mock turtle said to herself, and the mock turtle said to herself, and the mock turtle sa==================================================\n",
      "Итерация #: 5\n",
      "Epoch 1/2\n",
      "1091/1091 [==============================] - 45s 41ms/step - loss: 1.1664\n",
      "Epoch 2/2\n",
      "1091/1091 [==============================] - 45s 41ms/step - loss: 1.1130\n",
      "Генерация из посева: ou, wont y\n",
      "ou, wont you, will you, wont you, will you, wont you, will you, wont you, will you, wont you, will you, wont you, will you, wont you, will you, wont you, will you, wont you, will you, wont you, will you, wont you, will you, wont you, will you, wont you, will y==================================================\n",
      "Итерация #: 6\n",
      "Epoch 1/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 1.0631\n",
      "Epoch 2/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 1.0160\n",
      "Генерация из посева: es.--tell \n",
      "es.--tell her to been them a large with one eyes, and the mouse was the mouse was the mouse was the mouse was the mouse was the mouse was the mouse was the mouse was the mouse was the mouse was the mouse was the mouse was the mouse was the mouse was the mouse ==================================================\n",
      "Итерация #: 7\n",
      "Epoch 1/2\n",
      "1091/1091 [==============================] - 44s 41ms/step - loss: 0.9692\n",
      "Epoch 2/2\n",
      "1091/1091 [==============================] - 45s 41ms/step - loss: 0.9239\n",
      "Генерация из посева: one of the\n",
      "one of the court, and said to the gryphon. i wish you were drink heard and the paper as he spoke. why, i should be a catch to the dormouse said, and was going on she changed in a long trat mares the next witness, and was going on she changed in a long trat mar==================================================\n",
      "Итерация #: 8\n",
      "Epoch 1/2\n",
      "1091/1091 [==============================] - 44s 40ms/step - loss: 0.8818\n",
      "Epoch 2/2\n",
      "1091/1091 [==============================] - 44s 41ms/step - loss: 0.8407\n",
      "Генерация из посева: t she migh\n",
      "t she might as well as she couldnt get them so shinging them alice doesnt to hild love; and he thanged alice. ive to be twe crind that she was so much and some minutes it put to dreat them so shinging them alice doesnt to hild love; and he thanged alice. ive t==================================================\n",
      "Итерация #: 9\n",
      "Epoch 1/2\n",
      "1091/1091 [==============================] - 43s 40ms/step - loss: 0.8008\n",
      "Epoch 2/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 0.7611\n",
      "Генерация из посева:  thats a f\n",
      " thats a feet again, and when she found herself stay dont seem to have the reason is, that its eat the sea, the mock turtle soup in the time she had been to her, and the moral of that is--be what you wouldnt tell you wont thought that it was only thought it wo==================================================\n",
      "Итерация #: 10\n",
      "Epoch 1/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 0.7262\n",
      "Epoch 2/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 0.6922\n",
      "Генерация из посева:  you? said\n",
      " you? said alice, who had been to the peaple, and the white rabbit was no one tostion. its a mineral, and was going to dishersed to the gryphon replied very politely, and she had not attended to this little histories as i beline, and she had not attended to th==================================================\n",
      "Итерация #: 11\n",
      "Epoch 1/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 0.6588\n",
      "Epoch 2/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 0.6290\n",
      "Генерация из посева: d, and she\n",
      "d, and she was quite a naw--out after thin. i never think they live at the bottom of a well? take some more there was a general clarting their elss shout of the wind, and was going to herself, in a shrill, because of this worng sholl that it ever have such a n==================================================\n",
      "Итерация #: 12\n",
      "Epoch 1/2\n",
      "1091/1091 [==============================] - 45s 42ms/step - loss: 0.6018\n",
      "Epoch 2/2\n",
      "1091/1091 [==============================] - 44s 41ms/step - loss: 0.5750\n",
      "Генерация из посева:  all the f\n",
      " all the first really this could not remember, said the caterpillar. it would be worth the trouble of course, the mock turtle replied, so eagetly speaking, said the caterpillar. it would be worth the trouble of course, the mock turtle replied, so eagetly speak==================================================\n",
      "Итерация #: 13\n",
      "Epoch 1/2\n",
      "1091/1091 [==============================] - 47s 43ms/step - loss: 0.5525\n",
      "Epoch 2/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 0.5294\n",
      "Генерация из посева:  latitude \n",
      " latitude or longitude ive got to go through next walking about, and shouting off with his nose to look about her at any rate a bit, said the gryphon as if he had a ban, some with the time she had got its meant all the rest of the singers to the duchess took n==================================================\n",
      "Итерация #: 14\n",
      "Epoch 1/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 0.5101\n",
      "Epoch 2/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 0.4917\n",
      "Генерация из посева: y it out l\n",
      "y it out louding that she was looking at the cook took the opportunity of saying to her very much of a globe of goldfish kept raning in his turn; and behind it when she felt that it was over, and she felt that it was over, and she felt that it was over, and sh==================================================\n",
      "Итерация #: 15\n",
      "Epoch 1/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 0.4755\n",
      "Epoch 2/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 0.4612\n",
      "Генерация из посева:  had tired\n",
      " had tired herself this is bill, the lizards slate-pencer--i livery then old a low crowd alime, the king said to alice, and sighing. it isnt mine, said the cat, and vanished compontunity of showing off her unfortunate gardeners, or three times over to the othe==================================================\n",
      "Итерация #: 16\n",
      "Epoch 1/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 0.4493\n",
      "Epoch 2/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 0.4368\n",
      "Генерация из посева: or that le\n",
      "or that led into a small passage, not much surprised at this, that she was now merning ille its things as i sadd. will the mouse was sitting next to her. its a chostiop in her hands or her to speak to this mousente cat in the world she was quite pale (with pas==================================================\n",
      "Итерация #: 17\n",
      "Epoch 1/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 0.4266\n",
      "Epoch 2/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 0.4168\n",
      "Генерация из посева: elf useful\n",
      "elf useful, and looked at the stick, and had come to the conclusion, that it seemed quite naiked it, and found the fan, and she went on, what would happen next. first, she said to herself, i wonder? as the top of her head through the grownd watch! she remarked==================================================\n",
      "Итерация #: 18\n",
      "Epoch 1/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 0.4063\n",
      "Epoch 2/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 0.4000\n",
      "Генерация из посева:  mock turt\n",
      " mock turtle said with some severity; its very rude. the hatter. you must remember thats not at all a pity. i shall sit here, the footman continued as follows when the white rabbit, who was trembling voice, looking down a very dechap vyice, and then at once; b==================================================\n",
      "Итерация #: 19\n",
      "Epoch 1/2\n",
      "1091/1091 [==============================] - 45s 41ms/step - loss: 0.3935\n",
      "Epoch 2/2\n",
      "1091/1091 [==============================] - 45s 41ms/step - loss: 0.3858\n",
      "Генерация из посева: lad!--here\n",
      "lad!--here, put em up at this corner--no, tie ever thing the king said to the jury. not yet, not yet! the rabbit say to itself, oh dear! i shall be a great deal to i mead, the king said to the jury. not yet, not yet! the rabbit say to itself, oh dear! i shall ==================================================\n",
      "Итерация #: 20\n",
      "Epoch 1/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 0.3813\n",
      "Epoch 2/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 0.3751\n",
      "Генерация из посева: enly upon \n",
      "enly upon an opp! alice asked. we called her esg of disations continued the gryphon went on without a moment to be true): if she should chance to be involved in this affair, he trusts to you to set them orts and waistly at the moment how large she had found th==================================================\n",
      "Итерация #: 21\n",
      "Epoch 1/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 0.3698\n",
      "Epoch 2/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 0.3646\n",
      "Генерация из посева:  gave him \n",
      " gave him two-- why, that must be a walrus or hippopotatule in at the reason and all the players all played at once set to work throwing an inknttling the king said gravely, i think, said alice. ive so now about this, and after a minute or two she stood saided==================================================\n",
      "Итерация #: 22\n",
      "Epoch 1/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 0.3618\n",
      "Epoch 2/2\n",
      "1091/1091 [==============================] - 45s 42ms/step - loss: 0.3571\n",
      "Генерация из посева: had made h\n",
      "had made her next remark. its allay to get out again, and all of them before the trials beginning to see its mean, and alice was beginning to see its mean, and alice was beginning to see its mean, and alice was beginning to see its mean, and alice was beginnin==================================================\n",
      "Итерация #: 23\n",
      "Epoch 1/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 0.3536\n",
      "Epoch 2/2\n",
      "1091/1091 [==============================] - 46s 42ms/step - loss: 0.3504\n",
      "Генерация из посева: poor alice\n",
      "poor alice, that it made out the words came very queer to me. you! said alice, and she trought to find that the moral of that is--be what you wont thought alice, and she trought to find that the moral of that is--be what you wont thought alice, and she trought"
     ]
    }
   ],
   "source": [
    "# выполнение серий тренировочных и демонстрационных итераций \n",
    "for iteration in range(NUM_ITERATIONS):\n",
    "\n",
    "    # для каждой итерации запуск передачи данных в модель \n",
    "    print(\"=\" * 50)\n",
    "    print(\"Итерация #: %d\" % (iteration+1))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "\n",
    "    # Select a random example input sequence.\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "\n",
    "    # для числа шагов предсказаний использование текущей тренируемой модели \n",
    "    # конструирование one-hot encoding для тестирования input и добавление предсказания.\n",
    "    print(\"Генерация из посева: %s\" % (test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "\n",
    "        # здесь one-hot encoding.\n",
    "        X_test = np.zeros((1, SEQLEN, nb_chars))\n",
    "        for j, ch in enumerate(test_chars):\n",
    "            X_test[0, j, char2index[ch]] = 1\n",
    "\n",
    "        # осуществление предсказания с помощью текущей модели.\n",
    "        pred = model.predict(X_test, verbose=0)[0]\n",
    "        y_pred = index2char[np.argmax(pred)]\n",
    "\n",
    "        # вывод предсказания добавленного к тестовому примеру \n",
    "        print(y_pred, end=\"\")\n",
    "\n",
    "        # инкрементация тестового примера содержащего предсказание\n",
    "        test_chars = test_chars[1:] + y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Задание 2\n",
    "Попробуйте изменить параметры нейронной сети, генерирующей текст таким образом,\n",
    "чтобы добиться генерации как можно более осмысленного текста. Пришлите лучший\n",
    "текст из получившихся и опишите предпринятые для его получения действия. Можно\n",
    "использовать текст другого произведения."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-561ef815a61c>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m\"<ipython-input-11-561ef815a61c>\"\u001B[1;36m, line \u001B[1;32m2\u001B[0m\n\u001B[1;33m    Попробуйте изменить параметры нейронной сети, генерирующей текст таким образом,\u001B[0m\n\u001B[1;37m               ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### отрывок\n",
    "that was linked into herself, and began to repeat it, but have made a dreadful time, said the caterpillar took the hookah out of its mouth off, but she did not like to be told so. its really dreadful, she muttered to herself, and began to"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Предложения\n",
    "1. Убрать из текста книги главки\n",
    "2. Увеличить объем выборки\n",
    "3. Увеличить размер бачей\n",
    "4. Увеличить количество итераций и эпох\n",
    "\n",
    "Мне кажется что чем больше данных будет иметь алгоритм тем больше вероятность построения правильных предложений"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Lesson 5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}